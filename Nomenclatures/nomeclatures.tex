% Abbreviations
\nomenclature[z-RL]{RL}{Reinforcement learning}
\nomenclature[z-IL]{IL}{Imitation learning}
\nomenclature[z-BC]{BC}{Behavior cloning}
\nomenclature[z-IRL]{IRL}{Inverse reinforcement learning}

% Symbols
\nomenclature[a-01]{$\mathrm{Pr}(X = x)$}{probability that a random variable $X$ takes on the value $x$}
\nomenclature[a-02]{$X \sim p$}{random variable X selected from distribution \(p(x) = \mathrm{Pr}(X=x)\)}
\nomenclature[a-03]{$\mathbb{E}[X]$}{expectation of a random variable $X$}
\nomenclature[a-04]{$e^x$}{the base of the natural logarithm, $e \approx 2.71828$, carried to power $x$}
\nomenclature[a-05]{$\mathbb{R}$}{set of real numbers}
\nomenclature[a-06]{$\mathbbm{1}(a)$}{indicator function ($\mathbbm{1}(a) = 1$ if $a$ is true, else 0)}

\nomenclature[a-21]{$s, s'$}{states}
\nomenclature[a-22]{$a$}{an action}
\nomenclature[a-23]{$r$}{a reward}
\nomenclature[a-24]{$\mathcal{S}$}{set of all states}
\nomenclature[a-25]{$\mathcal{A}(s)$}{set of all actions available in state $s$}
\nomenclature[a-26]{$P(s' | s, a)$}{probability of transition to state $s'$, from state $s$ taking action $a$}
\nomenclature[a-27]{$\gamma$}{discount factor}
\nomenclature[a-28]{$H$}{final time step of an episode, or the length of an episode}
\nomenclature[a-29]{$\pi{a|s}$}{probability of tacking action $a$ in state $s$}

\nomenclature[a-41]{$t$}{discrete time step}
\nomenclature[a-43]{$s^t$}{state at time $t$}
\nomenclature[a-44]{$a^t$}{action at time $t$}
\nomenclature[a-45]{$r^t$}{reward at time $t$}
