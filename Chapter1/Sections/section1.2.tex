Based on the primary goal,
the work present in the dissertation resulted in three novel imitation learning agents.
These agents are summarized as follows:

\begin{itemize}
  \item
        The \DAIL\ agent is presented to address the domain adaptation in imitation learning.
        In order to overcome the domain shift problem,
        an objective function is designed based on adversarial learning in order to allow the agent to extract domain-shared and domain-specific features.
        These features are utilized to improve the agent's performance across different domains.

  \item
        The task adaptation problem is then considered by introducing \TAIL\ agent.
        The agent is trained using a similar objective function as \DAIL\.
        The experiment results demonstrate the agent's effectiveness in adapting the learned knowledge from a source task to a new target task.

  \item
        The result of \DAIL\ and \TAIL\ highlights the potential of adversarial learning in improving generalization in imitation learning.
        Thus,
        to further extend its capability,
        the \DTAIL\ agent and an adaptation method are proposed to tackle both domain and task adaptation problems in imitation learning.
        Being inspired by the idea of repetition learning in neuroscience,
        the proposed adaptation method enables the \DTAIL\ agent to repeatedly review the learned knowledge of the source task while learning the new knowledge of the target task.
        This ensures that the learning performance on the target task is high while the deterioration of the learning performance on the source task is small.
        A comprehensive evaluation over several simulated tasks with varying difficulty levels shows that the proposed method can provide high and consistent performance on both source and target tasks across different domains.
\end{itemize}
